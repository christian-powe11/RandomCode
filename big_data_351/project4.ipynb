{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 4)\n",
      "(20000, 4)\n"
     ]
    }
   ],
   "source": [
    "# pain gaming :/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import collections \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "file_path1 = r'C:\\Users\\chris\\Git Hub Repositories\\RandomCode\\big_data_351\\ml-100k\\u1.base'\n",
    "file_path2 = r'C:\\Users\\chris\\Git Hub Repositories\\RandomCode\\big_data_351\\ml-100k\\u1.test'\n",
    "training = pd.read_table(file_path1, header = None)\n",
    "testing = pd.read_table(file_path2, header=None)\n",
    "training.columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "testing.columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "\n",
    "print(training.shape)\n",
    "print(testing.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.drop('timestamp', axis=1)\n",
    "testing = testing.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique ratings are [1, 2, 3, 4, 5]\n",
      "The unique ratings are [1, 2, 3, 4, 5]\n",
      "user_id    0\n",
      "item_id    0\n",
      "rating     0\n",
      "dtype: int64\n",
      "user_id    0\n",
      "item_id    0\n",
      "rating     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The unique ratings are', sorted(training['rating'].unique()))\n",
    "print('The unique ratings are', sorted(testing['rating'].unique()))\n",
    "\n",
    "print(training.isna().sum())\n",
    "print(testing.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1650)\n",
      "(459, 1410)\n"
     ]
    }
   ],
   "source": [
    "user_matrix_train = training.pivot(index='user_id', columns = 'item_id', values = 'rating').fillna(0)\n",
    "user_matrix_test = testing.pivot(index='user_id', columns = 'item_id', values = 'rating').fillna(0)\n",
    "print(user_matrix_train.shape)\n",
    "print(user_matrix_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "user_similarity = cosine_similarity(user_matrix_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn.fit(user_matrix_train)\n",
    "k = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: User 823: distance 0.5942714921431335\n",
      "2: User 514: distance 0.6051806198568939\n",
      "3: User 864: distance 0.6182083336186182\n",
      "4: User 592: distance 0.6282865762239555\n",
      "5: User 521: distance 0.6322421003918934\n",
      "6: User 727: distance 0.6322528075400943\n",
      "7: User 889: distance 0.6332368238640443\n",
      "8: User 606: distance 0.6350963462175611\n",
      "9: User 622: distance 0.6359585689756575\n"
     ]
    }
   ],
   "source": [
    "input = 1\n",
    "user_index = input -1\n",
    "\n",
    "distances, indices = knn.kneighbors(user_matrix_train.iloc[user_index, :].values.reshape(1, -1), n_neighbors = k)\n",
    "\n",
    "for i in range(1, len(distances.flatten())):\n",
    "    print('{0}: User {1}: distance {2}'.format(i, user_matrix_train.index[indices.flatten()[i]], distances.flatten()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 822, 513, 863, 591, 520, 726, 888, 605, 621], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_matrix_train.iloc[822][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = 0\n",
    "\n",
    "\n",
    "for index, row in testing.iterrows():\n",
    "    movie = row['item_id']\n",
    "    distances, indices = knn.kneighbors(user_matrix_train.iloc[row['user_id'], :].values.reshape(1, -1), n_neighbors = k)\n",
    "    neighbor_ratings_sum = 0\n",
    "    counter = 0\n",
    "    for neighbor in indices.flatten():\n",
    "        try: \n",
    "            their_rating = user_matrix_train.iloc[row['user_id']][movie]\n",
    "            neighbor_ratings_sum += their_rating\n",
    "            counter += 1 \n",
    "        except:\n",
    "            pass\n",
    "    if counter != 0:\n",
    "        avg = neighbor_ratings_sum/counter\n",
    "        difference_local = (row['rating'] - avg)**2\n",
    "        mse = mse + difference_local\n",
    "    else:\n",
    "        mse = mse + (row['rating'])**2\n",
    "\n",
    "adjusted_mse = 1/20000 * mse \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-based collaborative filtering, a method used in recommendation systems, has its distinct strengths and drawbacks. Among its primary advantages are personalization, community wisdom, and the ability to function without item metadata. It personalizes recommendations by considering the preferences of users with similar tastes, thereby leveraging the collective wisdom of the community. This method does not require detailed information about the items themselves, making it versatile in situations where such data is scarce or unavailable.\n",
    "\n",
    "However, this approach also faces significant challenges. One of the key drawbacks is its struggle with scalability, especially in large datasets where calculating and maintaining user similarities becomes computationally intensive. Another major limitation is the cold start problem, where the system cannot effectively provide recommendations for new users due to a lack of their historical data. Additionally, user-based collaborative filtering often exhibits a popularity bias, tending to recommend items that are popular among users but potentially overlooking less common items that might be of interest.\n",
    "\n",
    "In essence, while user-based collaborative filtering excels in providing personalized recommendations and capitalizes on user ratings without needing item data, it is constrained by issues related to scalability, the new user problem, and a tendency to favor popular items. These factors need to be carefully considered when implementing this model in a real-world context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
